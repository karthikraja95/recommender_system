{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob70DFdS2ErB"
   },
   "source": [
    "In this notebook, you will obtain an introductory acquiantiance to baseline recommendation algorithms and evaluation methods.\n",
    "The recommendation dataset we will be using is from a collection called MovieLens, which contains usersâ€™ movie ratings and is popular for implementing and testing recommender systems. The specific dataset we will be using for this lab is MovieLens 100K Dataset which contains 100,000 movie ratings from 943 users and a selection of 1682 movies. In recommendation research works, usually a larger version of this dataset, MovieLens 20M is used instead.\n",
    "First, we import the necessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50nqYwXN1uBm",
    "outputId": "5a858e0c-616f-4a46-deaf-2fe8b45d3930"
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "# !pip install wget\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from math import sqrt\n",
    "from heapq import nlargest\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from scipy.linalg import sqrtm\n",
    "from dotmap import DotMap\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKROKg9u2twB"
   },
   "source": [
    "Downloading the dataset and have a glance on its statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MWLqiqSR2s0n"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/ssd003/projects/aieng/public/recsys_datasets/kasandr/de\"\n",
    "\n",
    "train_path = os.path.join(DATA_PATH, r'train_de.csv')\n",
    "# test_path = os.path.join(DATA_PATH, r'test_de.csv')\n",
    "\n",
    "df_train = pd.read_csv(train_path, delimiter = '\\t')\n",
    "# df_test = pd.read_csv(test_path, delimiter = '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = DotMap()\n",
    "\n",
    "args.min_uc = 5\n",
    "args.max_uc = 1000\n",
    "args.min_mc = 5\n",
    "args.min_us_prod_types = 10\n",
    "\n",
    "\n",
    "def sample_by_user(df, sample_rate=0.05):\n",
    "    user_list = list(set(df['userid']))\n",
    "    sampled_users = random.sample(user_list, math.floor(len(user_list)*sample_rate))\n",
    "    df = df[df['userid'].isin(sampled_users)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_min_mc(df):\n",
    "    \"\"\"removes the movie records that have been rated less frequent than minimun\n",
    "\n",
    "    Args:\n",
    "        df (pd.Dataframe): a pandas dataframe including uid, sid, rating, timestamp, \n",
    "        title, and genre)\n",
    "\n",
    "    Returns:\n",
    "        df (pd.Dataframe): the updated dataframe\n",
    "    \"\"\"\n",
    "    if args.min_mc > 0:\n",
    "            item_sizes = df.groupby('offerid').size()\n",
    "            good_items = item_sizes.index[item_sizes >= args.min_mc]\n",
    "            df = df[df['offerid'].isin(good_items)]\n",
    "    return df\n",
    "\n",
    "def filter_min_uc(df):\n",
    "    \"\"\"removes the user records that have rated less frequent than minimun\n",
    "\n",
    "    Args:\n",
    "        df (pd.Dataframe): a pandas dataframe including uid, sid, rating, timestamp, \n",
    "        title, and genre)\n",
    "\n",
    "    Returns:\n",
    "        df (pd.Dataframe): the updated dataframe\n",
    "    \"\"\"\n",
    "    if args.min_uc > 0:\n",
    "            user_sizes = df.groupby('userid').size()\n",
    "            good_users = user_sizes.index[user_sizes >= args.min_uc]\n",
    "            df = df[df['userid'].isin(good_users)]\n",
    "    return df\n",
    "\n",
    "def filter_max_uc(df):\n",
    "    \"\"\"removes the user records that have too many records\n",
    "\n",
    "    Args:\n",
    "        df (pd.Dataframe): a pandas dataframe including uid, sid, rating, timestamp, \n",
    "        title, and genre)\n",
    "\n",
    "    Returns:\n",
    "        df (pd.Dataframe): the updated dataframe\n",
    "    \"\"\"\n",
    "    if args.max_uc > 0:\n",
    "            user_sizes = df.groupby('userid').size()\n",
    "            good_users = user_sizes.index[user_sizes <= args.max_uc]\n",
    "            df = df[df['userid'].isin(good_users)]\n",
    "    return df\n",
    "\n",
    "def filter_min_user_product_types(df, prod_types=args.min_us_prod_types):\n",
    "    if prod_types > 0:\n",
    "            user_num_products = df[df['rating'] == 1].groupby('userid')['offerid'].agg(unique_count='nunique').reset_index()\n",
    "            \n",
    "            good_users = user_num_products[user_num_products['unique_count'] >= prod_types]['userid']\n",
    "            df = df[df['userid'].isin(good_users)]\n",
    "    return df\n",
    "\n",
    "def filter_single_label(df):\n",
    "    user_num_products = df.groupby('userid')['rating'].agg(rating_types='nunique').reset_index()\n",
    "    good_users = user_num_products[user_num_products['rating_types'] >= 2]['userid']\n",
    "    df = df[df['userid'].isin(good_users)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def densify_index(df):\n",
    "    \"\"\"reassigns the user and movie ids to remove the gaps caused by deletions\n",
    "\n",
    "    Args:\n",
    "        df (pd.Dataframe): a pandas dataframe including uid, sid, rating, timestamp, \n",
    "        title, and genre)\n",
    "\n",
    "    Returns:\n",
    "        df (pd.Dataframe): the updated dataframe\n",
    "    \"\"\"\n",
    "    umap = {u: i for i, u in enumerate(set(df['userid']), 1)}\n",
    "    smap = {s: i for i, s in enumerate(set(df['offerid']), 1)}\n",
    "    df['userid'] = df['userid'].map(umap)\n",
    "    df['offerid'] = df['offerid'].map(smap)\n",
    "    return df, umap, smap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_sampled = sample_by_user(df_train)\n",
    "# df_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd003/projects/aieng/public/recsys/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2384648</th>\n",
       "      <td>1</td>\n",
       "      <td>21080</td>\n",
       "      <td>0</td>\n",
       "      <td>1464792760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121032</th>\n",
       "      <td>1</td>\n",
       "      <td>6914</td>\n",
       "      <td>0</td>\n",
       "      <td>1464792760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166752</th>\n",
       "      <td>1</td>\n",
       "      <td>20031</td>\n",
       "      <td>0</td>\n",
       "      <td>1464792760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166753</th>\n",
       "      <td>1</td>\n",
       "      <td>2412</td>\n",
       "      <td>0</td>\n",
       "      <td>1464792760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5401241</th>\n",
       "      <td>1</td>\n",
       "      <td>17342</td>\n",
       "      <td>0</td>\n",
       "      <td>1464792760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10127061</th>\n",
       "      <td>418</td>\n",
       "      <td>6660</td>\n",
       "      <td>0</td>\n",
       "      <td>1465722712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12571164</th>\n",
       "      <td>418</td>\n",
       "      <td>16855</td>\n",
       "      <td>0</td>\n",
       "      <td>1465722712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14707063</th>\n",
       "      <td>418</td>\n",
       "      <td>17100</td>\n",
       "      <td>0</td>\n",
       "      <td>1465722712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14788638</th>\n",
       "      <td>418</td>\n",
       "      <td>14266</td>\n",
       "      <td>0</td>\n",
       "      <td>1465722712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9573783</th>\n",
       "      <td>418</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>1465722769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49142 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userID  itemID  rating   timestamp\n",
       "2384648        1   21080       0  1464792760\n",
       "4121032        1    6914       0  1464792760\n",
       "5166752        1   20031       0  1464792760\n",
       "5166753        1    2412       0  1464792760\n",
       "5401241        1   17342       0  1464792760\n",
       "...          ...     ...     ...         ...\n",
       "10127061     418    6660       0  1465722712\n",
       "12571164     418   16855       0  1465722712\n",
       "14707063     418   17100       0  1465722712\n",
       "14788638     418   14266       0  1465722712\n",
       "9573783      418    1995       1  1465722769\n",
       "\n",
       "[49142 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_preprocessing(df):\n",
    "    df = filter_min_mc(df)\n",
    "    df = filter_min_uc(df)\n",
    "    df = filter_max_uc(df)\n",
    "    df = filter_min_user_product_types(df)\n",
    "    df = filter_single_label(df)\n",
    "    df, umap, smap = densify_index(df)\n",
    "\n",
    "    df['utcdate']= pd.to_datetime(df['utcdate'])\n",
    "    df['timestamp'] = df['utcdate'].astype('int64') // 10 ** 9\n",
    "\n",
    "    df.rename(columns={'userid':'userID',\n",
    "                        'offerid':'itemID'}, inplace=True)\n",
    "    \n",
    "    # reassign label to fit model format\n",
    "#     df.loc[df['rating'] == 1, 'rating'] = 2\n",
    "#     df.loc[df['rating'] == 0, 'rating'] = 1    \n",
    "\n",
    "    df = df[['userID','itemID','rating','timestamp']]\n",
    "    df = df.sort_values(by=['userID', 'timestamp'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df2 = data_preprocessing(df_train)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5166753</th>\n",
       "      <td>1</td>\n",
       "      <td>2412</td>\n",
       "      <td>0</td>\n",
       "      <td>1464792760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955282</th>\n",
       "      <td>1</td>\n",
       "      <td>6900</td>\n",
       "      <td>0</td>\n",
       "      <td>1464792760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12706217</th>\n",
       "      <td>1</td>\n",
       "      <td>13366</td>\n",
       "      <td>0</td>\n",
       "      <td>1464792760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12223720</th>\n",
       "      <td>1</td>\n",
       "      <td>9317</td>\n",
       "      <td>0</td>\n",
       "      <td>1464792760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955295</th>\n",
       "      <td>1</td>\n",
       "      <td>15862</td>\n",
       "      <td>1</td>\n",
       "      <td>1464792859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10127061</th>\n",
       "      <td>418</td>\n",
       "      <td>6660</td>\n",
       "      <td>0</td>\n",
       "      <td>1465722712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180755</th>\n",
       "      <td>418</td>\n",
       "      <td>18893</td>\n",
       "      <td>0</td>\n",
       "      <td>1465722712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552123</th>\n",
       "      <td>418</td>\n",
       "      <td>9357</td>\n",
       "      <td>1</td>\n",
       "      <td>1465722712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495560</th>\n",
       "      <td>418</td>\n",
       "      <td>14210</td>\n",
       "      <td>0</td>\n",
       "      <td>1465722712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9573783</th>\n",
       "      <td>418</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>1465722769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29484 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userID  itemID  rating   timestamp\n",
       "5166753        1    2412       0  1464792760\n",
       "5955282        1    6900       0  1464792760\n",
       "12706217       1   13366       0  1464792760\n",
       "12223720       1    9317       0  1464792760\n",
       "5955295        1   15862       1  1464792859\n",
       "...          ...     ...     ...         ...\n",
       "10127061     418    6660       0  1465722712\n",
       "1180755      418   18893       0  1465722712\n",
       "3552123      418    9357       1  1465722712\n",
       "1495560      418   14210       0  1465722712\n",
       "9573783      418    1995       1  1465722769\n",
       "\n",
       "[29484 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = df2.copy()\n",
    "rating_df_train, rating_df_test = train_test_split(rating_df, test_size=0.2)\n",
    "rating_df_train, rating_df_val = train_test_split(rating_df_train, test_size=0.25)\n",
    "\n",
    "def sort_data(df):\n",
    "    return df.sort_values(by=['userID', 'timestamp'])\n",
    "\n",
    "rating_df_train = sort_data(rating_df_train)\n",
    "rating_df_test = sort_data(rating_df_test)\n",
    "rating_df_val = sort_data(rating_df_val)\n",
    "\n",
    "rating_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23209360635185958\n"
     ]
    }
   ],
   "source": [
    "data_threshold = len(rating_df_train.loc[rating_df_train.rating == 1])/len(rating_df_train.loc[rating_df_train.rating == 0])\n",
    "print(data_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD, BaselineOnly\n",
    "from surprise.model_selection import cross_validate\n",
    " \n",
    "# Get minimum and maximum rating from the dataset\n",
    "min_rating = rating_df_train.rating.min()\n",
    "max_rating = rating_df_train.rating.max()\n",
    " \n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "data = Dataset.load_from_df(rating_df_train[['userID', 'itemID', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.3095  0.3021  0.3047  0.3052  0.3027  0.3048  0.0026  \n",
      "MAE (testset)     0.2006  0.1928  0.1983  0.1963  0.1962  0.1968  0.0026  \n",
      "Fit time          0.79    0.79    0.79    0.79    0.80    0.79    0.00    \n",
      "Test time         0.04    0.15    0.04    0.04    0.04    0.06    0.04    \n"
     ]
    }
   ],
   "source": [
    "svd = SVD(n_epochs=10)\n",
    "results = cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28102772108044655\n",
      "{'n_factors': 100, 'n_epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    " \n",
    "param_grid = {\n",
    "  'n_factors': [20, 50, 100],\n",
    "  'n_epochs': [5, 10, 20]\n",
    "}\n",
    " \n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=10)\n",
    "gs.fit(data)\n",
    " \n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    " \n",
    "# best hyperparameters\n",
    "best_factor = gs.best_params['rmse']['n_factors']\n",
    "best_epoch = gs.best_params['rmse']['n_epochs']\n",
    "\n",
    "# best_factor = 100\n",
    "# best_epoch = 20\n",
    " \n",
    "# sample random trainset and testset\n",
    "# test set is made of 20% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=.20)\n",
    " \n",
    "# # We'll use the famous SVD algorithm.\n",
    "# svd = SVD(n_factors=best_factor, n_epochs=best_epoch)\n",
    " \n",
    "# # Train the algorithm on the trainset\n",
    "# svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=None):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    ndcgs = dict()\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        \n",
    "        # NDCG@K\n",
    "        # Note current implementation of NDCG is not accurate due to very few positive samples in testing set\n",
    "        \n",
    "        est_list, label_list = zip(*user_ratings)\n",
    "        est_list = [list(est_list)]\n",
    "        label_list = [list(label_list)]\n",
    "        \n",
    "        try:\n",
    "            ndcgs[uid] = ndcg_score(est_list, label_list, k=k)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return precisions, recalls, ndcgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "average precision@1:0.6106420279362023\n",
      "average recall@1:0.29303506796947665\n",
      "average ndcg@1:0.8471005984246862\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "average precision@3:0.5787585267402294\n",
      "average recall@3:0.4038735965654509\n",
      "average ndcg@3:0.8714687675401814\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "average precision@5:0.5606893899184489\n",
      "average recall@5:0.46599609476988696\n",
      "average ndcg@5:0.8854021550927585\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "# algo = SVD()\n",
    "algo = BaselineOnly()\n",
    "\n",
    "prec_list = []\n",
    "rec_list = []\n",
    "ndcg_list = []\n",
    "metrics_val = [1,3,5]\n",
    "\n",
    "for i in metrics_val:\n",
    "    for trainset, testset in kf.split(data):\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "        precisions, recalls, ndcgs = precision_recall_at_k(predictions, k=i, threshold=data_threshold)\n",
    "\n",
    "    #     # Precision and recall can then be averaged over all users\n",
    "    #     print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    #     print(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "\n",
    "        prec_list.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        rec_list.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "        ndcg_list.append(sum(ndcg for ndcg in ndcgs.values()) / len(ndcgs))\n",
    "        \n",
    "    \n",
    "    print(\"average precision@{}:\".format(i) + str(np.mean(prec_list)))\n",
    "    print(\"average recall@{}:\".format(i) + str(np.mean(rec_list)))\n",
    "    print(\"average ndcg@{}:\".format(i) + str(np.mean(ndcg_list)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_est_true = defaultdict(list)\n",
    "for uid, _, true_r, est, _ in predictions:\n",
    "    user_est_true[uid].append((est, true_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_list, label_list = zip(*user_est_true[1069])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981556457588459"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_score(est_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
